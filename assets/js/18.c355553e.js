(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{469:function(e,t,r){"use strict";r.r(t);var n=r(7),a=Object(n.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"machine-learning"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#machine-learning"}},[e._v("#")]),e._v(" Machine Learning")]),e._v(" "),r("p",[e._v("A highly opinionated ML cheat sheet.")]),e._v(" "),r("h2",{attrs:{id:"getting-started"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#getting-started"}},[e._v("#")]),e._v(" Getting Started")]),e._v(" "),r("ul",[r("li",[e._v("Deep Learning Demystified, by "),r("a",{attrs:{href:"https://brohrer.github.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Brandon Rohrer"),r("OutboundLink")],1),e._v(":\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://brohrer.github.io/deep_learning_demystified.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("How Neural Networks work?"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://brohrer.github.io/how_convolutional_neural_networks_work.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("How Convolutional Neural Networks work?"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("A Neural Network in 15 lines of Python, by "),r("a",{attrs:{href:"https://twitter.com/iamtrask",target:"_blank",rel:"noopener noreferrer"}},[e._v("Andrew Trask"),r("OutboundLink")],1),e._v(":\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://iamtrask.github.io/2015/07/12/basic-python-network/",target:"_blank",rel:"noopener noreferrer"}},[e._v("basic Neural Network in 11 lines"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://iamtrask.github.io/2015/07/27/python-network-part2/",target:"_blank",rel:"noopener noreferrer"}},[e._v("adding Gradient Descent Optimizer"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://iamtrask.github.io/2015/07/28/dropout/",target:"_blank",rel:"noopener noreferrer"}},[e._v("adding Hinston's Dropout"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Understanding the maths behind Deep Learning, with code implementations:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://theclevermachine.wordpress.com/2014/09/11/a-gentle-introduction-to-artificial-neural-networks/",target:"_blank",rel:"noopener noreferrer"}},[e._v("A Gentle Introduction to Artificial Neural Networks"),r("OutboundLink")],1),e._v(" by "),r("a",{attrs:{href:"https://twitter.com/corrcoef",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dustin Stansbury"),r("OutboundLink")],1)]),e._v(" "),r("li",[e._v("Machine Learning, by "),r("a",{attrs:{href:"http://andrew.gibiansky.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Andrew Gibiansky"),r("OutboundLink")],1),e._v(":\n"),r("ul",[r("li",[r("a",{attrs:{href:"http://andrew.gibiansky.com/blog/machine-learning/machine-learning-the-basics/",target:"_blank",rel:"noopener noreferrer"}},[e._v("The bascics"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://andrew.gibiansky.com/blog/machine-learning/machine-learning-neural-networks/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Neural Networks"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Convolutional Neural Networks"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://andrew.gibiansky.com/blog/machine-learning/recurrent-neural-networks/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Recurrent Neural Networks"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Neural Networks and Deep Learning"),r("OutboundLink")],1),e._v(" by "),r("a",{attrs:{href:"https://twitter.com/michael_nielsen",target:"_blank",rel:"noopener noreferrer"}},[e._v("Michael Nielsen"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Gentlest Introduction to Tensorflow, by "),r("a",{attrs:{href:"https://twitter.com/neth_6",target:"_blank",rel:"noopener noreferrer"}},[e._v("Soon Hin Khor"),r("OutboundLink")],1),e._v(":\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://medium.com/all-of-us-are-belong-to-machines/the-gentlest-introduction-to-tensorflow-248dc871a224#.pbfs8sxmz",target:"_blank",rel:"noopener noreferrer"}},[e._v("Linear regression for single feature single outcome model"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://medium.com/all-of-us-are-belong-to-machines/gentlest-introduction-to-tensorflow-part-2-ed2a0a7a624f#.eerdfyjcs",target:"_blank",rel:"noopener noreferrer"}},[e._v("Training illustrated in diagrams/code, and exploring training variations"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"https://medium.com/all-of-us-are-belong-to-machines/gentlest-intro-to-tensorflow-part-3-matrices-multi-feature-linear-regression-30a81ebaaa6c#.1c6z3z79z",target:"_blank",rel:"noopener noreferrer"}},[e._v("Matrices and multi-feature linear regression"),r("OutboundLink")],1)])])]),e._v(" "),r("li",[e._v("Practical Examples:\n"),r("ul",[r("li",[r("a",{attrs:{href:"https://medium.com/xeneta/boosting-sales-with-machine-learning-fbcf2e618be3#.192b2lj98",target:"_blank",rel:"noopener noreferrer"}},[e._v("Qualifying sales leads"),r("OutboundLink")],1),e._v(", by "),r("a",{attrs:{href:"https://twitter.com/perborgen",target:"_blank",rel:"noopener noreferrer"}},[e._v("Per Harald Borgen"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://dlacombejr.github.io/2016/11/13/deep-learning-for-regex.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Deep Learning for RegEx"),r("OutboundLink")],1)])])])]),e._v(" "),r("h2",{attrs:{id:"regression"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#regression"}},[e._v("#")]),e._v(" Regression")]),e._v(" "),r("h3",{attrs:{id:"neural-network"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#neural-network"}},[e._v("#")]),e._v(" Neural Network")]),e._v(" "),r("p",[e._v('Neural Networks can approximate any function, by applying an "activation" function to a bias plus the weighted sum of inputs: '),r("code",[e._v("y = σ(b + Σwx)")]),e._v(".")]),e._v(" "),r("p",[e._v('Since for any probability problem there exists a function to calculate it, Neural Networks can be used to automatically\nfind that function using meaningful "training" data and a "learning" algorithm such as the Stochastic Gradient Descent:')]),e._v(" "),r("ol",[r("li",[e._v("initialize weights and biases")]),e._v(" "),r("li",[e._v("calculate a prediction for the given training input")]),e._v(" "),r("li",[e._v("calculate the pediction error, using the expected output from the training data")]),e._v(" "),r("li",[e._v("calculate the Gradient of the error")]),e._v(" "),r("li",[e._v("adjust weights and biases with the gradient, then repeat from step 2 for a given number of epochs")])]),e._v(" "),r("h4",{attrs:{id:"_1-weights-biases-initialization"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-weights-biases-initialization"}},[e._v("#")]),e._v(" 1. Weights/Biases Initialization")]),e._v(" "),r("p",[e._v("Depending on the chosen activation function, initialize weights and biases as follow:")]),e._v(" "),r("ul",[r("li",[e._v("for sigmoid (standard, tanh): Gaussian distribution with mean 0 and standard deviation:\n"),r("ul",[r("li",[e._v("1 for each bias (so it's picked randomly between -1 and 1 with mean 0)")]),e._v(" "),r("li",[e._v("1 / √n for each weight with n being the number of neurons in the layer\n(using a standard deviation of 1 with a high number of neurons result with a saturated layers,\nand saturated layers are slow learners)")])])]),e._v(" "),r("li",[e._v("for the rest (softmax, ReLU, etc): all weights and biases set to 0")])]),e._v(" "),r("blockquote",[r("p",[r("strong",[e._v("Tip")]),e._v(": For debugging, seed random numbers to make calculation deterministic.")])]),e._v(" "),r("p",[e._v("See: "),r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/chap3.html#weight_initialization",target:"_blank",rel:"noopener noreferrer"}},[e._v("Weight Initialization"),r("OutboundLink")],1)]),e._v(" "),r("h4",{attrs:{id:"_2-activation-function"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-activation-function"}},[e._v("#")]),e._v(" 2. Activation Function")]),e._v(" "),r("p",[e._v("For regression problems, a standard sigmoid function (also known as logistic function) can be used for activation:\n"),r("code",[e._v("sigmoid(y) = 1 / 1 + exp(-y)")]),e._v(", it ranges from 0 (saturates near -6) to 1 (saturates near 6).")]),e._v(" "),r("p",[e._v("Sometimes the Hyperbolic Tangent (tanh) function performs better: "),r("code",[e._v("tanh(y) = (exp(y) - exp(-y)) / (exp(y) + exp(-y))")]),e._v(",\nit ranges from -1 (saturates near -3) to 1 (saturates near 3).")]),e._v(" "),r("p",[e._v("Rectified Linear Unit (ReLU) often improve results when used on image recognition problems: "),r("code",[e._v("relu(y) = max(0, y)")]),e._v(",\nit returns 0 for negative sum of weighted input, otherwise it returns the sum of weighted input.")]),e._v(" "),r("p",[e._v("Finally the softmax function is used in classification problems, where there are many outputs:\n"),r("code",[e._v("softmax(yj) = exp(zj) / Σexp(zk)")]),e._v(". The output of a neuron "),r("code",[e._v("j")]),e._v(" is the exponential function of its sum of weighted input,\ndivided by the sum of all the output neurons. This means the total of all output neurons will always be 1.")]),e._v(" "),r("p",[e._v("References:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/chap1.html#sigmoid_neurons",target:"_blank",rel:"noopener noreferrer"}},[e._v("Sigmoid neurons"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/chap3.html#softmax",target:"_blank",rel:"noopener noreferrer"}},[e._v("softmax"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/chap3.html#other_models_of_artificial_neuron",target:"_blank",rel:"noopener noreferrer"}},[e._v("Other models of artificial neuron"),r("OutboundLink")],1)])]),e._v(" "),r("h4",{attrs:{id:"_3-error-function"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-error-function"}},[e._v("#")]),e._v(" 3. Error Function")]),e._v(" "),r("p",[e._v("For regression problems, the cross entropy cost function is usually used.")]),e._v(" "),r("blockquote",[r("p",[r("strong",[e._v("Note")]),e._v(": The quadratic cost (aka Mean Squarred Error) function is often used in examples: as it is easier to learn\nthan the cross entropy, however it isn't as efficient.")])]),e._v(" "),r("p",[e._v("For classification problems, the log-likelihood function is used.")]),e._v(" "),r("p",[e._v("References:")]),e._v(" "),r("ul",[r("li",[r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/chap1.html#learning_with_gradient_descent",target:"_blank",rel:"noopener noreferrer"}},[e._v("Learning with gradient"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/chap3.html#the_cross-entropy_cost_function",target:"_blank",rel:"noopener noreferrer"}},[e._v("The cross entropy function"),r("OutboundLink")],1)]),e._v(" "),r("li",[r("a",{attrs:{href:"http://neuralnetworksanddeeplearning.com/chap3.html#softmax",target:"_blank",rel:"noopener noreferrer"}},[e._v("Softmax and log-likelihood"),r("OutboundLink")],1)])]),e._v(" "),r("h4",{attrs:{id:"_4-gradient"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-gradient"}},[e._v("#")]),e._v(" 4. Gradient")]),e._v(" "),r("h4",{attrs:{id:"_5-epochs"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-epochs"}},[e._v("#")]),e._v(" 5. Epochs")]),e._v(" "),r("h4",{attrs:{id:"data"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#data"}},[e._v("#")]),e._v(" Data")]),e._v(" "),r("p",[e._v("In order to train our network, we need examples that map input to an expected output. We can split it in 3 sets:")]),e._v(" "),r("ol",[r("li",[e._v("Training set: 70% of the examples,\nthe mean error will be used with the Gradient to modify parameters (weights and biases)")]),e._v(" "),r("li",[e._v("Validating set: 15% of the examples,\nthe mean error will be used to stop the training once saturated,\nit's purpose is to evaluate hyper parameters and prevent overfitting on training data")]),e._v(" "),r("li",[e._v("Testing set: 15% of the examples,\nthe mean error will be used to evaluate parameters (weights and biases) and prevent overfitting on testing data")])]),e._v(" "),r("h4",{attrs:{id:"overfitting"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#overfitting"}},[e._v("#")]),e._v(" Overfitting")]),e._v(" "),r("p",[e._v("Overfitting is when our model optimizes for our training data but fails to be useful for new unknown data.\nTo prevent this from happening, we can:")]),e._v(" "),r("ul",[r("li",[e._v("increase the amount of training data")]),e._v(" "),r("li",[e._v("use L2 regularlization")]),e._v(" "),r("li",[e._v("use L1 regularlization")]),e._v(" "),r("li",[e._v("use dropout")])]),e._v(" "),r("h2",{attrs:{id:"classification"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#classification"}},[e._v("#")]),e._v(" Classification")]),e._v(" "),r("h3",{attrs:{id:"bag-of-words-model"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#bag-of-words-model"}},[e._v("#")]),e._v(" Bag of Words Model")]),e._v(" "),r("p",[e._v("Assuming the occurence of each words can be used as a feature for training a classifier.")]),e._v(" "),r("h4",{attrs:{id:"how-it-works"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#how-it-works"}},[e._v("#")]),e._v(" How it works")]),e._v(" "),r("ol",[r("li",[e._v('fitting: "learn" vocabulary by extracting each words from all sentences')]),e._v(" "),r("li",[e._v("transforming: extract vocabulary word count for each sentence")]),e._v(" "),r("li",[e._v("optionally keep only the most x used words")])]),e._v(" "),r("h4",{attrs:{id:"reference"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#reference"}},[e._v("#")]),e._v(" Reference")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words",target:"_blank",rel:"noopener noreferrer"}},[e._v("Bag of Words for beginners"),r("OutboundLink")],1),e._v("\nby "),r("a",{attrs:{href:"https://www.kaggle.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Kaggle"),r("OutboundLink")],1)]),e._v(" "),r("h3",{attrs:{id:"naive-bayes-classifier"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#naive-bayes-classifier"}},[e._v("#")]),e._v(" Naive Bayes Classifier")]),e._v(" "),r("p",[e._v("Assuming that a statement probability of being of a certain type depends if this type is more likely\nand if the statement contains more words of this type.")]),e._v(" "),r("h4",{attrs:{id:"how-it-works-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#how-it-works-2"}},[e._v("#")]),e._v(" How it works")]),e._v(" "),r("ol",[r("li",[e._v('"learning" types:\n'),r("ul",[r("li",[e._v("count the total number of documents")]),e._v(" "),r("li",[e._v("count how many times a word from a statement occurs for a given type")])])]),e._v(" "),r("li",[e._v('"guessing" types:\n'),r("ul",[r("li",[e._v("calculate type probability: count of documents of this type / total count of documents")]),e._v(" "),r("li",[e._v("calculate statement type probability: for each words in the statements\n"),r("ul",[r("li",[e._v("calculate word type probability: count occurence of this word for this type / total number of words")]),e._v(" "),r("li",[e._v("multiply all word type probabilities")])])]),e._v(" "),r("li",[e._v("calculate likelihood: multiply type probability by statement type probability")]),e._v(" "),r("li",[e._v("the statement is likely being of the type that has the highest likelihood")])])])]),e._v(" "),r("h4",{attrs:{id:"reference-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#reference-2"}},[e._v("#")]),e._v(" Reference")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://stovepipe.systems/post/machine-learning-naive-bayes",target:"_blank",rel:"noopener noreferrer"}},[e._v("Machine Learning: Naive Bayes"),r("OutboundLink")],1),e._v(",\nby "),r("a",{attrs:{href:"https://twitter.com/yannickl88",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yannick de Lange"),r("OutboundLink")],1)]),e._v(" "),r("h3",{attrs:{id:"random-forest-classifier"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#random-forest-classifier"}},[e._v("#")]),e._v(" Random Forest Classifier")]),e._v(" "),r("h4",{attrs:{id:"how-it-works-3"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#how-it-works-3"}},[e._v("#")]),e._v(" How it works")]),e._v(" "),r("ol",[r("li",[e._v('"training":\n'),r("ul",[r("li",[e._v("take a subset (~66%) of the data")]),e._v(" "),r("li",[e._v("for each node:\n"),r("ul",[r("li",[e._v("take randomly "),r("em",[e._v("m")]),e._v(" items from the subset")]),e._v(" "),r("li",[e._v("pick the item that provides the best split and use it to do a binary split on that node")]),e._v(" "),r("li",[e._v("for the next node, do the same with another "),r("em",[e._v("m")]),e._v(" random items from the subset")])])])])]),e._v(" "),r("li",[e._v('"running":\n'),r("ul",[r("li",[e._v("run input down all the trees")]),e._v(" "),r("li",[e._v("take the average, or weighted average, or voting majority of all the results")])])])]),e._v(" "),r("blockquote",[r("p",[r("em",[e._v("m")]),e._v(" can be either (your choice):")]),e._v(" "),r("ul",[r("li",[e._v("1 (random splitter selection)")]),e._v(" "),r("li",[e._v("total number of items (breiman’s bagger)")]),e._v(" "),r("li",[e._v("something in between, e.g. ½√m, √m, and 2√m (random forest)")])])]),e._v(" "),r("h4",{attrs:{id:"reference-3"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#reference-3"}},[e._v("#")]),e._v(" Reference")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://citizennet.com/blog/2012/11/10/random-forests-ensembles-and-performance-metrics/",target:"_blank",rel:"noopener noreferrer"}},[e._v("A Gentle Introduction to Random Forests"),r("OutboundLink")],1),e._v(",\nby "),r("a",{attrs:{href:"https://twitter.com/dbenyamin",target:"_blank",rel:"noopener noreferrer"}},[e._v("Dan Benyamin"),r("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=a.exports}}]);