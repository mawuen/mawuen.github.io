(window.webpackJsonp=window.webpackJsonp||[]).push([[43],{491:function(a,s,t){"use strict";t.r(s);var e=t(7),n=Object(e.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"introduction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#introduction"}},[a._v("#")]),a._v(" Introduction")]),a._v(" "),t("p",[a._v("In my previous "),t("a",{attrs:{href:"https://mawuen.github.io/2012/02/05/installing-haskell-on-ubuntu-14-with-stack/",target:"_blank",rel:"noopener noreferrer"}},[a._v("post"),t("OutboundLink")],1),a._v(",\nI tried to provide a step-by-step explanation of how to install\n"),t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell",target:"_blank",rel:"noopener noreferrer"}},[a._v("IHaskell"),t("OutboundLink")],1),a._v(" on Ubuntu 14.04 (Should also\nwork on other versions). Now is time to start using it!")]),a._v(" "),t("p",[a._v("This post is not a quickstart on how to use IHaskell, as it has already been\ncovered in the "),t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell/blob/master/notebooks/IHaskell.ipynb",target:"_blank",rel:"noopener noreferrer"}},[a._v("official documentation"),t("OutboundLink")],1),a._v(".\nAnd there are more advanced examples here:")]),a._v(" "),t("ul",[t("li",[t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell/blob/master/notebooks/Conjugate%20Gradient.ipynb",target:"_blank",rel:"noopener noreferrer"}},[a._v("Conjugate Gradient"),t("OutboundLink")],1)]),a._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell/blob/master/notebooks/Gradient-Descent.ipynb",target:"_blank",rel:"noopener noreferrer"}},[a._v("Gradient Descent"),t("OutboundLink")],1)]),a._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell/blob/master/notebooks/Homophones.ipynb",target:"_blank",rel:"noopener noreferrer"}},[a._v("Homophones"),t("OutboundLink")],1)]),a._v(" "),t("li",[t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb",target:"_blank",rel:"noopener noreferrer"}},[a._v("Static Canvas IHaskell Display"),t("OutboundLink")],1)])]),a._v(" "),t("p",[a._v("Instead, I'll focus more on something a bit more mysterious for me:\n"),t("em",[a._v("displaying custom Haskell types in notebooks")]),a._v(". I'll first try to give a\nquick explanation on how it works, and then give basic examples of the\nprovided integrations with existing libraries (aeson, blaze, charts,\ndiagrams, etc.). I'll also try to show how to support your custom types.")]),a._v(" "),t("p",[t("strong",[a._v("Disclaimer")]),a._v(": Some of the information found in the post may be\nredundant with other sources (like official documentation, and in\nparticular the last post in the list above: "),t("em",[a._v("Static Canvas IHaskell\nDisplay")]),a._v("), but I hope this post will bring value by giving an overview\nof what is possible with "),t("em",[a._v("IHaskell")]),a._v(", explained with the words of a\nnewcomer. Comments and fixes would be greatly appreciated!")]),a._v(" "),t("h2",{attrs:{id:"how-does-it-work"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#how-does-it-work"}},[a._v("#")]),a._v(" How does it work?")]),a._v(" "),t("p",[a._v("Jupyter allows you to embed arbitrary HTML, and this mechanism is used\nby IHaskell to display values in custom ways. The "),t("code",[a._v("IHaskellDisplay")]),a._v("\ntypeclass is used to this effect. By providing an instance for\nyour own types, they can be displayed in notebooks (we'll see\nlater that some extensions already exist to provide such display\nto known Haskell libraries). A "),t("code",[a._v("Display")]),a._v(" can be of several types,\nbut for now we will focus on "),t("code",[a._v("html")]),a._v(" and "),t("code",[a._v("plain")]),a._v(" (see "),t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb",target:"_blank",rel:"noopener noreferrer"}},[a._v("this notebook"),t("OutboundLink")],1),a._v(" for more information).")]),a._v(" "),t("p",[a._v("Note that you can provide several choices of display outputs so that\nyour custom type can be display in notebooks "),t("em",[a._v("(html)")]),a._v(" or console "),t("em",[a._v("(plain\ntext)")]),a._v(", the frontend will then select the best choice.")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" IHaskell.Display")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Custom data type")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Answer")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Answer")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v('-- Make it "displayable"')]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("IHaskellDisplay")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Answer")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- List of two kinds of Display: html and plain text")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("display")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("value")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("return")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Display")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("htmlDisplay")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("txtDisplay")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- HTML Display")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("htmlDisplay")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("html")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"<div>The answer is 42!</div>"')]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Plain Text Display")]),a._v("\n            "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("txtDisplay")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("plain")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"42"')]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Display an instance of our type")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Answer")]),a._v("\n")])])]),t("blockquote",[t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("The answer is "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("!")]),a._v("\n")])])])]),a._v(" "),t("p",[a._v("In the following sections we'll see how to use some of the extensions\nofficially provided by "),t("em",[a._v("IHaskell")]),a._v(" to display types of known libraries.\nThe packages we'll need are:")]),a._v(" "),t("ul",[t("li",[a._v("ihaskell-basic")]),a._v(" "),t("li",[a._v("ihaskell-aeson")]),a._v(" "),t("li",[a._v("ihaskell-blaze")]),a._v(" "),t("li",[a._v("ihaskell-charts")]),a._v(" "),t("li",[a._v("ihaskell-diagrams")]),a._v(" "),t("li",[a._v("ihaskell-magic")])]),a._v(" "),t("p",[a._v("You can install them using stack if you intend to try this out yourself:")]),a._v(" "),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("stack build             "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    ihaskell-basic      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    ihaskell-aeson      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    ihaskell-blaze      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    ihaskell-charts     "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    ihaskell-diagrams   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("\n    ihaskell-magic\n")])])]),t("h2",{attrs:{id:"ihaskell-basic"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ihaskell-basic"}},[a._v("#")]),a._v(" ihaskell-basic")]),a._v(" "),t("p",[a._v("IHaskell "),t("a",{attrs:{href:"https://hackage.haskell.org/package/ihaskell-basic",target:"_blank",rel:"noopener noreferrer"}},[a._v("basic"),t("OutboundLink")],1),a._v(" contains\n"),t("em",[a._v('"Instances of IHaskellDisplay for default prelude data types"')]),a._v(". Currently,\nonly "),t("code",[a._v("Maybe")]),a._v(" seems to be supported. Maybe some more "),t("em",[a._v("Displays")]),a._v(" will be provided\nin the future?")]),a._v(" "),t("p",[a._v("Anyway, here is how you can use it, and what it looks like:")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- import IHaskell.Display.Basic")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Foo Bar Baz"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("\n")])])]),t("blockquote",[t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Just")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Foo Bar Baz"')]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Nothing")]),a._v("\n")])])])]),a._v(" "),t("h2",{attrs:{id:"ihaskell-aeson"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ihaskell-aeson"}},[a._v("#")]),a._v(" ihaskell-aeson")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://hackage.haskell.org/package/aeson",target:"_blank",rel:"noopener noreferrer"}},[a._v("Aeson"),t("OutboundLink")],1),a._v(" is a library used to\nmanipulate "),t("em",[a._v("JSON")]),a._v(" format from Haskell. It allows you to use "),t("code",[a._v("ToJSON")]),a._v(" and\n"),t("code",[a._v("FromJSON")]),a._v(" typeclasses to convert your custom data-types "),t("em",[a._v("to")]),a._v(" and "),t("em",[a._v("from")]),a._v("\nJSON format.")]),a._v(" "),t("p",[a._v("In our small example, we declare a type of document with an arbitrary\nnumber of metadata attached, here is how we could do it:")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("OverloadedStrings")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Data.Text "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" T")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Data.Aeson "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" A")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- IHaskell.Display.Aeson")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("newtype")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Property")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Property")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("T.Text")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("newtype")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Value")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Value")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("T.Text")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Property")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Value")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("newtype")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Body")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Body")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("T.Text")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("newtype")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("T.Text")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Document")]),a._v("  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Document")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Title")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_body")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Body")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Metadata")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A.ToJSON")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n   "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("toJSON")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("d")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("A.object")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("v")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Property")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("p")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Value")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("v")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("d")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A.ToJSON")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Document")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n   "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("toJSON")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Document")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Body")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("A.object")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("\n       "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"title"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("t")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n       "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"body"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n       "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"metadata"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("A.toJSON")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("m")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("document")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("body")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Body")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Lorem Ipsum"')]),a._v("\n               "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Foo Bar"')]),a._v("\n               "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("\n                   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Property")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Encoding"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Value")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"UTF-8"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n                   "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Property")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Author"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Value")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Jonh Doe"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n           "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Document")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_title")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("title")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_body")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("body")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("_metadata")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("metadata")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A.Null")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("A.Bool")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("A.toJSON")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("document")]),a._v("\n")])])]),t("blockquote",[t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("null")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("true")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"body"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Lorem Ipsum"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"metadata"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Author"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Jonh Doe"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n        "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Encoding"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"UTF-8"')]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"title"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Foo Bar"')]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n")])])])]),a._v(" "),t("h2",{attrs:{id:"ihaskell-blaze"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ihaskell-blaze"}},[a._v("#")]),a._v(" ihaskell-blaze")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://hackage.haskell.org/package/blaze-html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Blaze"),t("OutboundLink")],1),a._v(" is a fast combinator library used to assemble "),t("em",[a._v("HTML")]),a._v(" documents directly in Haskell code "),t("em",[a._v("("),t("a",{attrs:{href:"https://wiki.haskell.org/Embedded_domain_specific_language",target:"_blank",rel:"noopener noreferrer"}},[a._v("Embedded Domain Specific Language"),t("OutboundLink")],1),a._v(")")]),a._v(". According to the official description, "),t("em",[a._v('"the project is aimed at those who seek to write web applications in Haskell â€“ it integrates well with all Haskell web frameworks."')])]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- This example if from the IHaskell official introduction")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("OverloadedStrings")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- import IHaskell.Display.Blaze")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Control.Monad")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Prelude "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("hiding")])]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("div")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("id")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Text.Blaze.Html4.Strict "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" B")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Text.Blaze.Html4.Strict.Attributes "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" A")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("forM")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("B.toValue")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("size")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("70")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("B.img")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".!")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("A.src")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"https://www.google.com/images/srpr/logo11w.png"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".!")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("A.width")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v("\n")])])]),t("img",{attrs:{src:"/assets/posts/google-logo.png",width:"70"}}),a._v(" "),t("img",{attrs:{src:"/assets/posts/google-logo.png",width:"140"}}),a._v(" "),t("img",{attrs:{src:"/assets/posts/google-logo.png",width:"210"}}),a._v(" "),t("img",{attrs:{src:"/assets/posts/google-logo.png",width:"280"}}),a._v(" "),t("img",{attrs:{src:"/assets/posts/google-logo.png",width:"350"}}),a._v(" "),t("h2",{attrs:{id:"ihaskell-charts"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ihaskell-charts"}},[a._v("#")]),a._v(" ihaskell-charts")]),a._v(" "),t("p",[t("a",{attrs:{href:"https://hackage.haskell.org/package/Chart",target:"_blank",rel:"noopener noreferrer"}},[a._v("Charts"),t("OutboundLink")],1),a._v(" is a "),t("em",[a._v('"2D charting library for haskell"')]),a._v(". Here a two examples taken from the "),t("a",{attrs:{href:"https://github.com/timbod7/haskell-chart/wiki",target:"_blank",rel:"noopener noreferrer"}},[a._v("official wiki"),t("OutboundLink")],1),a._v(" on github. To adapt examples to notebooks, you must replace any reference of "),t("code",[a._v("toFile")]),a._v(", etc. by "),t("code",[a._v("toRenderable")]),a._v(".")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- This example is taken from the wiki: https://github.com/timbod7/haskell-chart/wiki/example%205")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Graphics.Rendering.Chart.Easy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" E")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("values")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("String")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Bool")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("values")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Mexico City"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("19.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Mumbai"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("12.9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Sydney"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"London"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8.3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n         "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"New York"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("pitem")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("v")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("o")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.pitem_value")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("v")]),a._v("\n              "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.pitem_label")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v("\n              "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.pitem_offset")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("if")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("o")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("then")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("25")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("else")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n              "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.def")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.toRenderable")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.pie_title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Relative Population"')]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.pie_plot")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.pie_data")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..~")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("map")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("pitem")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("values")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.def")]),a._v("\n")])])]),t("p",[t("img",{attrs:{src:"/assets/posts/ihaskell-chart.svg",alt:"pie chart"}})]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- This example is taken from the wiki: https://github.com/timbod7/haskell-chart/wiki/example%2012")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Graphics.Rendering.Chart.Easy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" E")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),a._v("' "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("z")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("sqrt")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("z")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("efield")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("sign")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("sign")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("sign")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),a._v("' "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bfield")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("sign")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("sign")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("sign")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("/")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("^")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("r")]),a._v("' "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("square")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("range")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("s")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Double")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("add")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("ef")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("efield")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("`add`")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("efield")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bf")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bfield")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("`add`")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bfield")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("x")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("y")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("grid")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("square")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("30")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("vectorField")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("grid")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("fmap")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plotVectorField")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.liftEC")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<-")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.takeColor")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plot_vectors_mapf")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("f")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plot_vectors_grid")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("grid")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plot_vectors_style")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.vector_line_style")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.line_color")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plot_vectors_style")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.vector_head_style")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(" . ")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.point_color")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("c")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plot_vectors_title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("title")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("main")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.toRenderable")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.setColors")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.opaque")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.black")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.opaque")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.blue")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.layout_title")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("E")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Positive and Negative Charges"')]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plot")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("vectorField")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Electric Field"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("ef")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("grid")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("E.plot")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("vectorField")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"B-field"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("bf")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("grid")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("main")]),a._v("\n")])])]),t("p",[t("img",{attrs:{src:"/assets/posts/ihaskell-field.svg",alt:"field"}})]),a._v(" "),t("h2",{attrs:{id:"ihaskell-diagrams"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ihaskell-diagrams"}},[a._v("#")]),a._v(" ihaskell-diagrams")]),a._v(" "),t("p",[t("a",{attrs:{href:"http://projects.haskell.org/diagrams/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Diagrams"),t("OutboundLink")],1),a._v(" is a "),t("em",[a._v('"powerful, flexible, declarative domain-specific language for creating vector graphics"')]),a._v(". That is, it provides a flexible embedded DSL used to describe vectorized figures that you can then render using different backends.")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("NoMonomorphismRestriction")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("FlexibleContexts")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("GADTs")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Diagrams.Prelude "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" D")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Diagrams.TwoD.Sunburst "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" S")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Data.Tree")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("unfoldTree")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("aTree")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("unfoldTree")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("\\")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("n")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("->")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("replicate")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("n")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("n")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("diagram")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("S.sunburst")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("aTree")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("D")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".#")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("D.centerXY")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("D")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".#")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("D.pad")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.1")]),a._v("\n")])])]),t("p",[t("img",{attrs:{src:"/assets/posts/ihaskell-diagram1.svg",alt:"field"}})]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- import Diagrams.Backend.SVG.CmdLine as")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Diagrams.Prelude "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" D")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Diagrams.TwoD.Factorization "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" F")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("diagram")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("F.fdGridList")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("D")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".#")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("D.center")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("D")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(".#")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("D.pad")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.05")]),a._v("\n")])])]),t("p",[t("img",{attrs:{src:"/assets/posts/ihaskell-diagram2.svg",alt:"field"}})]),a._v(" "),t("h2",{attrs:{id:"ihaskell-magic"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ihaskell-magic"}},[a._v("#")]),a._v(" ihaskell-magic")]),a._v(" "),t("p",[a._v("In this case, libmagic is used to determine type of files using magic\nvalues at the beginning, which allows us to display binary content in\nnotebooks, in the right way. For example, if we want to display an\nimage (png, jpeg, svg, etc.), we just have to read its content as a\n"),t("code",[a._v("ByteString")]),a._v(", then "),t("code",[a._v("libmagic")]),a._v(" is used behind the scene by "),t("em",[a._v("IHaskell")]),a._v(" to\ndetermine what kind of content it is, based on the magic bytes present\nin the file, and then inline it in the notebook.")]),a._v(" "),t("p",[a._v("What is important to understand here, is that an instance of\nIHaskellDisplay is defined for both "),t("code",[a._v("ByteString")]),a._v(" and "),t("code",[a._v("Text")]),a._v(", in case\nthis strings represent something else than text (images, for example),\n"),t("em",[a._v("IHaskell")]),a._v(" is able to know it thanks to "),t("code",[a._v("libmagic")]),a._v(" and display the content\naccordingly, otherwise, it just displays the string.")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Data.ByteString "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" B")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("readFile")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"./haskell-logo.png"')]),a._v("\n")])])]),t("p",[t("img",{attrs:{src:"/assets/posts/output_25_0.png",alt:"Haskell logo"}})]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("OverloadedStrings")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Data.ByteString "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" B")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"This is a string of type ByteString"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("B.ByteString")]),a._v("\n")])])]),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("This is a string of "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("type")]),a._v(" ByteString\n")])])]),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("OverloadedStrings")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("qualified")]),a._v(" Data.Text "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" T")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"This is a string of type Text"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("T.Text")]),a._v("\n")])])]),t("div",{staticClass:"language-sh extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sh"}},[t("code",[a._v("This is a string of "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("type")]),a._v(" Text\n")])])]),t("h2",{attrs:{id:"ihaskell-static-canvas"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ihaskell-static-canvas"}},[a._v("#")]),a._v(" ihaskell-static-canvas")]),a._v(" "),t("p",[a._v("Following on the "),t("a",{attrs:{href:"https://github.com/gibiansky/IHaskell/blob/master/notebooks/Static%20Canvas%20IHaskell%20Display.ipynb",target:"_blank",rel:"noopener noreferrer"}},[a._v("excellent introduction"),t("OutboundLink")],1),a._v("\nfrom the author of "),t("em",[a._v("IHaskell")]),a._v(". Let's try to use\n"),t("a",{attrs:{href:"https://github.com/jeffreyrosenbluth/static-canvas",target:"_blank",rel:"noopener noreferrer"}},[a._v("static-canvas"),t("OutboundLink")],1),a._v(" to\ncreate more elaborate inlings in notebooks! The github page is full\nof "),t("a",{attrs:{href:""}},[a._v("examples")]),a._v(" that we can try out right now. But before that, we\nmust create an instance of "),t("code",[a._v("IHaskellDisplay")]),a._v(" for "),t("code",[a._v("CanvasFree")]),a._v(" (which\nis taken directly from the mentionned tutorial (I hope it's Ok, since\n"),t("code",[a._v("ihaskell-static-canvas")]),a._v(" doesn't seem to be part of Stackage LTS at the\nmoment).")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" IHaskell.Display")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- From the 'ihaskell' package.")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" IHaskell.IPython.Types")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("MimeType")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Graphics.Static")]),a._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- From the 'static-canvas' package.")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Text conversion functions.")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Data.Text.Lazy.Builder")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("toLazyText")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Data.Text.Lazy")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("toStrict")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- Since CanvasFree is a type synonym, we need a language pragma.")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("TypeSynonymInstances")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("extension")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("FlexibleInstances")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("instance")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("IHaskellDisplay")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("CanvasFree")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("-- display :: CanvasFree () -> IO Display")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("display")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("canvas")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("return")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("src")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("toStrict")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("toLazyText")]),a._v("\n      "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("$")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("buildScript")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("width")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("height")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("canvas")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("Display")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("DisplayData")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("MimeHtml")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("src")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("where")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("height")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("width")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("200")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("600")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("Now let's try some example:")]),a._v(" "),t("div",{staticClass:"language-haskell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-haskell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Graphics.Static")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token import_statement"}},[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" Graphics.Static.ColorNames")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("text")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("::")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("CanvasFree")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("text")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("do")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("font")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"italic 60pt Calibri"')]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("lineWidth")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("strokeStyle")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("blue")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fillStyle")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("goldenrod")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("textBaseline")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[a._v("TextBaselineMiddle")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("strokeText")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Haskell"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("150")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),a._v("\n  "),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("fillText")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Haskell!"')]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("150")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("100")]),a._v("\n\n"),t("span",{pre:!0,attrs:{class:"token hvariable"}},[a._v("text")]),a._v("\n")])])]),t("p",[t("img",{attrs:{src:"/assets/posts/ihaskell-canvas.png",alt:""}})]),a._v(" "),t("h2",{attrs:{id:"conclusion"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#conclusion"}},[a._v("#")]),a._v(" Conclusion")]),a._v(" "),t("p",[a._v("This was a short introduction without much new stuff, but it gave me a\nbetter understanding on how "),t("em",[a._v("IHaskell")]),a._v(" (and in a way, "),t("em",[a._v("Jupyter")]),a._v(") works.\nThanks to the awesome work of some haskellers, we are able to benefit\nfrom the great "),t("em",[a._v("Jupyter")]),a._v(" ecosystem, and I think it can bring a lot to\n"),t("em",[a._v("Haskell")]),a._v(" itself. It's easier to share code, easier to write about\n"),t("em",[a._v("Haskell")]),a._v("-related stuff, easier to dig into a new projet.")]),a._v(" "),t("p",[t("em",[a._v("IHaskell")]),a._v(" is a solid foundation for more to come: more widgets, more\nintegrations with "),t("em",[a._v("Haskell")]),a._v(" libraries, etc. I wonder if, for example, we\ncould use "),t("em",[a._v("Blaze")]),a._v(" to generate "),t("em",[a._v("Display")]),a._v(" on-the-fly? Could we reuse some\ncode from the "),t("em",[a._v("Python")]),a._v(" Kernel of "),t("em",[a._v("Jupyter")]),a._v("? I'm also looking forward to\ntry the "),t("code",[a._v("ihaskell-widgets")]),a._v(" extension.")]),a._v(" "),t("p",[a._v("That's pretty much it, I'd like to say I'm very excited for Haskell,\nbecause it becomes much more accessible for newcomers, thanks to (for\nexample) Stack, IHaskell, and lot of effort that is being made by the\ncommunity. I hope I can continue to contribute at my level to this\neffort!")]),a._v(" "),t("p",[a._v("Thanks for reading!")])])}),[],!1,null,null,null);s.default=n.exports}}]);